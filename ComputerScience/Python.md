# 1장 변수
## 핵심키워드
### 프로그램
- '데이터'를 입력받아 연산,처리한 후 다시 '데이터'를 출력한다.
### 메모리
- 입력받은 데이터가 저장되는 공간이다.
### 변수
- 메모리에서의 데이터 위치를 나타낸다.

<br/><br/><br/>

## 메모리 미리보기
- 컴퓨터는 1과 0으로 이루어진 데이터를 처리한다. <br/>이때 1과 0을 표현할 수 있는 데이터 단위를 비트(bit)라고 부른다. <br/>1비트는 0혹은 1이다.<br/>
비트가 8개 보이면 바이트(byte)라고 부른다. <br/>1바이트는 01011010과 같이 0과 1이 총 8개로 구성되어 있다.<br/><br/>
- 컴퓨터를 살 때 램(RAM)의 크기에 대해 이야기하는 걸 들어본 적이 있을 것이다. <br/> 기가바이트(GB)는 1,024x1,024x1,024 = 1,073,741,824 바이트를 의미한다. <br/>정말 많은 데이터를 저장할 수 있다.<br/><br/>
- 요즘은 64비트 컴퓨터가 대부분이라 램으로 12GB나 16GB를 사용할 수 있지만, 32비트 컴퓨터를 사용했을 때는 4GB가 넘는 램을 추가로 설치해도 실제 사용할 수 있는 램은 4GB 뿐이다.

<br/>

### 32비트와 64비트의 의미
- 컴퓨터는 데이터 단위로 비트를 사용한다.<br/><br/>
- 한 번에 보낼 수 있는 데이터 개수가 32비트면 32비트 컴퓨터고, 64비트면 64비트 컴퓨터이다. <br/>또한, 32비트 컴퓨터는 메모리 주소를 32비트로 표현하고, 64비트 컴퓨터는 64비트로 표현한다.<br/><br/>

<br/>

### 메모리에 우편번호를 매긴다
- 컴퓨터는 0과 1밖에 모르므로 컴퓨터에 주소를 알려 주려면 주소도 2진수로 나타내야 한다. <br/>메모리 주소 한 개는 메모리에서 1바이크를 가리킨다. <br/>우편번호 한 개가 일정 구역 한 곳을 가리키듯이 말이다.<br/><br/>
- 한 개 동을 나타내는 우편번호가 각각 있듯이 1바이트 메모리를 나타내는 메모리 주소가 각각 있다.<br/><br/>
- 32비트 컴퓨터라면 주소 하나를 나타내는 데 2진수 서른 두 자릿수를 사용한다. <br/>그러므로 32비트에서 나타낼 수 있는 주소 개수는 2<sup>32</sup>개 이다.<br/><br/>
- 메모리 주소 한 개는 1바이트를 가리키므로 32비트로는 2<sup>32</sup>바이트를 표현할 수 있다. <br/>다시 4,294,967,296바이트는 4×1,024×1,024×1,024바이트로 풀어 쓸 수 있다. <br/>1,024바이트는 1KB, 1,024×1,024바이트는 1MB, 1,024×1,024×1,024바이트는 1GB이다.<br/><br/>
- 즉, 32비트로는 총 4GB 메모리를 가리킬 수 있다. <br/>이것이 바로 32비트 컴퓨터에서 4GB보다 큰 메모리가 무용지물인 이유이다.<br/><br/>
- 64비트 컴퓨터는 이론으로만 보면 2<sup>64</sup>바이트를 가리킬 수 있으므로 크기가 훨씬 큰 램을 설치해도 모두 사용할 수 있다.

<br/><br/><br/>

## 변수의 의미
- 변수(variable)란 데이터를 저장할 수 있는 메모리 공간을 의미한다. <br/>여기서 중요한 점은 변수가 단순한 이름이 아니라 메모리 공간 자체를 의미한다는 점이다. <br/>변수는 숫자와 문자뿐만 아니라 객체, 심지어 함수까지도 담을 수 있다. <br/>변수에 담긴 값이나 가리키는 대상은 언제라도 변경될 수 있다. <br/>변경될 수 있으므로 변수이다.<br/><br/>
- 단, 다른 언어에서 말하는 변수와 파이썬에서 말하는 변수는 약간 차이가 난다.
<pre><code>int num = 5;</code></pre>
- 위의 C언어에서 말하는 변수는 num이라는 '변수'에 5라는 '값'이 담겨 있다. <br/>직관적으로 알 수 있는 변수의 모습이다. <br/>하지만 파이썬에서 말하는 변수는 이 모습과 약간 다르다.

<br/><br/><br/>

## 파이썬에서의 변수: 이름과 값 객체
- 파이썬에서 쓰는 변수는 이름과 값 객체로 나눠진다. <br/>우리가 파이썬에서 변수라고 부르는 것은 사실 '이름'이다.
<pre><code>num = 5</code></pre>
- num이라는 '이름'은 5라는 '값 객체'를 가리킨다. <br/>num은 5라는 값을 담고 있는 메모리 공간을 의미하지 않는다. <br/>값 객체는 다른 메모리 공간에 있다.<br/><br/>
- 따라서 type(num)을 하게 되면 num이라는 변수의 타입이 상수가 아니라 int라는 클래스의 인스턴스(객체)라는 것을 알려준다.

---

<br/><br/><br/><br/>

# 2장 정수
- 수(number)는 컴퓨터가 다루는 데이터 종류(자료형)중 가장 중요하다. <br/>컴퓨터는 0과 1만 인식하므로 사람과 다른 방식으로 수를 표현한다.

<br/><br/><br/>

## 컴퓨터에서 수를 표현하는 방법
- 수를 표현하는 방법을 기수법(numeral system)이라고 한다. <br/>밑수를 정하면 밑수 개수만큼의 숫자(digit)를 사용해 수를 나타낼 수 있다. <br/>예를 들어 우리가 일상생활에서 사용하는 10진수는 밑수가 10이고 총 열 개의 숫자로 수를 표현한다.

<br/>

### 10진수
- 10진수는  수를 표현하는 데 숫자를 총 열 개 사용한다. 이때 밑수는 10이고 0부터 9까지 총 열 개의 숫자로 모든 수를 표현한다. 

<br/>

### 2진수
- 2진수는 수를 표현하는 데 숫자 0과 1만 사용한다. 컴퓨터가 인식할 수 있는 표현 방법이다.

<br/>

### 16진수
- 16진수는 수를 표현하는 데 숫자를 총 열여섯 개 사용한다. 숫자를 열여섯 개 사용하기 때문에 9 이후의 숫자는 알파벳 a~f로 표현한다. <br/><br/>
- 즉, 16진수는 `0,1,2,3,4,5,6,7,8,9,a,b,c,d,e,f`로 구성된다.

<br/><br/><br/>

## 10진수를 2진수로
<pre><code>bin(Number)</code></pre>
<pre><code>bin(25) # 0b11001</code></pre>
- bin() 함수는 정수를 2진수로 표현하는 함수이다. 결과 값 앞에 나오는 0b는 2진수를 의미하는 binary이다. <br/>변환된 2진수를 보면 앞에서 직접 변환한 값과 같다.<br/><br/>
- 16진수는 0x(hexadecimal)를 앞에 붙여 준다.

<br/><br/><br/>

## 코딩으로 확인하는 진수 변환
<pre><code>a=0xa
bin(a) # 0b1010

b=0xb
bin(b) # 0b1011

c=0xc
bin(c) # 0b1100

d=0xd
bin(d) # 0b1101

e=0xe
bin(e) # 0b1110

f=0xf
bin(f) # 0b1111</code></pre>

<br/>

- 8비트 컴퓨터의 메모리 주소가 2진수로 0010 1101이라면 2진수 네 자릿수를 16진수 한 자릿수로 표현할 수 있으므로 0x2d로 나타낼 수 있다.
<pre><code>address_8bit = 0b00101101
hex(address_8bit) # 0x2d</code></pre>

<br/>

- hex() 함수는 정수를 16진수로 표현한다. <br/>2진수로 표현하면 8비트를 표ㅎ현하는 데 여덟 자릿수가 필요하지만, 16진수로 표현하면 두 자릿수로 간단히 나타낼 수 있어 가독성을 높일 수 있다. <br/>이러한 이유로 메모리 주소를 나타낼 때는 16진수를 사용한다. <br/><br/>
- 32비트 컴퓨터는 서른두 자릿수의 2진수 수가 아닌 여덟 자릿수의 16진수 수를 이용해 표현한다.
<pre><code>address_32비트 = 0x1234abcd
bin(address_32비트) #'0b10010001101001010101111001101'</code></pre>

<br/><br/><br/>

## 양의 정수
- 컴퓨터는 정수(integer)를 1바이트, 2바이트, 4바이트, 8바이트 등 다양한 크기로 저장한다. <br/><br/>
- 정수에는 음수와 양수가 있으므로 부호를 나타내는 데 1비트를 사용한다. <br/>맨 앞의 비트가 0이면 양수, 1이면 음수이다.<br/><br/>
- 예를 들어 25를 메모리에 저장할 때 맨 앞의 비트는 양수이므로 0이 된다. <br/>10진수 25를 2진수로 변환하면 11001이므로 나머지 비트를 0으로 채우면 메모리에 00011001로 저장된다.<br/><br/>
- 맨 앞의 비트가 부호를 나타낸다는 사실만 알고 있다면 10진수를 2진수로 변환한 것과 같다.

<br/>

### 1바이트로 나타낼 수 있는 수의 크기는?
- 언뜻 생각했을 때 8비트를 사용하므로 2<sup>8</sup> 즉, 0 ~ 255일 것 같지만, 정수에는 음수가 포함되고 맨 앞의 비트를 부호로 사용하므로 표현할 수 있는 양수의 범위는 절반으로 줄어든다. <br/>즉, 1바이트로 나타낼 수 있는 수의 범위는 -128 ~ 127이다(음수를 취급하지 않아 0~255를 나타낼 수 있는 정수 자료형도 있다). <br/>하지만 음의 정수를 표현할 때는 방식이 많이 달라진다.

<br/><br/><br/>

## 음의 정수
- 컴퓨터가 음수를 보수(complement) 형태로 저장하므로 음의 정수가 어떻게 저장되는지 이해하려면 보수의 개념을 반드시 알아야 한다.

<br/>

### 보수의 개념
- 보수란 쉽게 말해 '보충해 주는 수'이다. <br/><br/>
- 예를 들어 10진수에서 9의 보수를 구한다고 가정하자. <br/>3의 9의 보수는 3을 더해 9가 되는 수인 6이다. <br/>26의 9의 보수는 73이다. <br/>즉, 어떤 수의 각 자릿수 수를 9에서 빼면 9의 보수를 구할 수 있다. <br/><br/>
- 10의 보수도 구해보자. <br/>3의 10의 보수는 9의 9의 보수인 6에 1을 더한 값인 7이다. <br/>26의 10의 보수는 9의 보수인 73에 1을 더한 값인 74이다.

<br/>

### 2의 보수
- 2진수 1010의 1의 보수는 0101이다. <br/>각 자릿수 수의 1과 0을 반전한 결과이다. <br/><br/>
- 이제 1010의 2의 보수를 구해보자. <br/>1010의 1의 보수가 0101이므로 여기에 1을 더하면 된다. <br/>즉, 1010의 2의 보수는 0110이다. <br/><br/>
- 2의 보수가 중요한 이유는 컴퓨터가 음수를 표현할 때 2의 보수를 사용하기 때문이다.

<br/>

### 음수의 표현
- 컴퓨터는 음수를 2의 보수로 표현한다. <br/><br/>
- 음수인 -4를 1111 1100으로 표현된다. <br/>4를 2진수(0000 0100)로 변환하고 1의 보수를 구한다. <br/>1에서 각 자릿수 수를 빼면(모든 비트를 반전하면) 1의 보수인 1111 1011을 구할 수 있다. <br/>이 수에 1을 더해 2의 보수를 구하면 최종 결과는 1111 1100이다.<br/><br/>

<pre><code>(-4).to_bytes(1, byteorder=‘little’, signed = True) # b’\xfc’</code></pre>
- 위의 코드는 -4라는 '정수'를 컴퓨터 메모리에 저장되는 '바이트'형태로 표현하는 코드이다. <br/>첫 번째 인자는 몇 바이트로 나타낼지 지정한다. <br/>두 번째 인자는 바이트 오더(byteorder)이다. <br/>마지막 인자인 signed는 양수와 음수를 모두 표현할지 아니면 양수만 표현할지 정하는 인수이다. <br/><br/>
- 출력 값은 16진수로 표현된다. 16진수 0xFC를 2진수로 변환하면 1111 1100이다. <br/> -4의 2의 보수와 같다. <br/>이로써 컴퓨터는 음수를 2의 보수를 이용해 저장한다는 것을 알 수 있다. <br/><br/>

- 바이트 오더는 빅 엔디언인지 아니면 리틀 엔디언인지 정하는 인자이다. 

<br/>

### 2의 보수로 표현하는 이유
1. 양수와 음수를 모두 양수처럼 저장한다고 가정해 보자. <br/>0000 0000과 1000 0000은 +0과 -0이 된다. <br/>즉, 0을 표현하는 두 가지 방법이 존재하게 된다. <br/>이렇게 되면 컴퓨터 입장에서는 수 하나를 더 표현할 수 있는데 비트 하나를 낭비하는 셈이다. <br/>또한 두 수를 비교할 때 CPU에서 뺄셈을 하는데 +0과 -0을 비교하면 결과 값이 예상과 다르게 나온다. <br/><br/>
2. 컴퓨터에서 정수의 뺄셈 과정을 살펴보자. <br/>덧셈은 단순히 두 수를 더하면 되지만, 뺄셈은 2의 보수 개념을 활용한다. <br/>9-4를 계산할 때 9에서 4를 빼는 게 아니라 9와 -4를 더한다. <br/><br/>

![image](https://user-images.githubusercontent.com/61584142/156593117-f9732024-70f0-4d31-9a93-19f7821db419.png)

- 10진수 9를 2진수로 표현한 0000 1001에서 10진수 -4를 2의 보수로 표현한 1111 1100을 더한다. <br/>계산 결과를 보면 받아올림(carrying)이 발생하여 1 0000 0101이 나오는데 이때 받아올림 수(맨 앞 의 1)는 버리면 된다. <br/>최종 결과는 0000 0101로 5가 된다. <br/>즉, 9-4가 잘 계산되었음을 알 수 있다. <br/>이와 같은 컴퓨터의 연산 방식을 알면 음수를 왜 2의 보수로 저장하는 지 이해할 수 있다.

---

<br/><br/><br/><br/>

# 3장 실수
## 실수 
<pre><code>a = 0.01
result = 0.0
for i in range(100):
  result += a
  result # 1.0000000000000007</code></pre>
- 이 코드를 보면 a가 0.01이고 이를 100번 더했으니 당연히 1이 나오기를 기대한다. 하지만 결과를 확인해 보면 예상과 다르다. <br/>1에 매우 가까운 수라고는 해도 1은 아니다. 

<br/>

<pre><code>a = 0.015625
a # 0.015625

result = 0.0

for i in range(100):
  result += a

result # 1.5625</code></pre>
- 이번에는 0.01을 100번 더하는 게 아니라 0.015625를 100번 더한다. <br/>컴퓨터가 실수를 표현하는 방법인 부동소수점으로 결과가 정확하게 나온다.

<br/><br/><br/>

## 부동소수점
- 컴퓨터는 IEEE(Institute of Electrical and Electronics Enginerrs, 전기전자기술자협회)까 1985년에 제정한 ANSI/IEEE 754-1985라는 표준에 따라 실수(real number)를 표현한다. <br/>이 표준에 따른 표현법을 부동소수점(floating-point)이라고 부르는데 여기서 '부'는 부표를 말할 때 쓰는 '부'로 둥둥 떠다닌다는 의미이다. <br/>소수점 위치를 보면 앞에 있기도 하고 뒤에 있기도 하다. <br/>마치 소수점이 떠다니는 것처럼 보인다고 해서 이러한 실수 표현 방식을 부동소수점이라고 부른다.

<br/><br/><br/>

## 단정도와 배정도
- 부동소수점에는 단정도 부동소수점과 배정도 부동소수점이 있다. <br/>단정도(single-precision)는 실수를 32비트(4바이트)로 표현하며 부호 1비트, 지수부 8비트, 가수부 23비트로 구성된다. <br/>배정도(double-precision)는 실수를 64비트(8바이트)로 표현하며 부호 1비트, 지수부 11비트, 가수부 52비트로 구성된다. <br/>실수를 표현하는 데 사용하는 비트 수가 단정도보다 두 배 많은 만큼 정밀도가 높다. <br/><br/>

- 파이썬은 배정도를 사용한다.

<pre><code>import sys
sys.float_info
# sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)</code></pre>
- sys라는 모듈을 임포트한 다음 float_info를 입력하면 최댓값, 최솟값, 정밀도 등을 확인할 수 있다.
<pre><code>sys.float_info.max # 1.7976931348623157e+308</code></pre>
<pre><code>sys.float_info.min # 2.2250738585072014e-308</code></pre>

<br/><br/><br/>

## 1바이트 실수 자료형 설계하기
- ± 1.man × 2<sup>exp - bias</sup>
- 1.man은 가수(mantissa/fraction), 2는 밑수, exp-bias는 지수(exponent)를 의미한다.

<br/>

### 10진수 실수를 2진수 실수로 바꾸기
- 7.75 = 4 + 2 + 1 + 0.5 + 0.25 <br/>= 2<sup>2</sup> + 2<sup>1</sup> + 2<sup>0</sup> + 2<sup>-1></sup> + 2<sup>-2</sup> <br/>= 111.11

<br/>

### 정규화
- 정규화(normalization)란 소수점 왼쪽에 위치한 가수 부분을 밑수보다 작은 자연수가 되도록 만드는 것이다. <br/>예를 들어 10진수 567.89를 정규화하면 소수점 왼쪽에 위치한 가수 부분이 밑수 10보다 작은 자연수 5가 되어 5.6789x10<sup>2</sup>이 된다. <br/><br/>
- 2진수의 밑수는 2이므로 2보다 작은 자연수는 1밖에 없다. <br/>따라서 소수점 왼쪽의 가수 부분은 항상 1이 된다. <br/>111.11을 정규화하면 다음과 같다. <br/>111.11 = 1.1111 x 2<sup>2</sup>

<br/>

### 메모리 구조
- 정규화된 부동소수점 수 1.1111 x 2<sup>2</sup>을 앞의 수식과 비교해 보면 man은 1111이고 exp -bias는 2이다. <br/>이제 1바이트의 메모리 구조를 정하고 man과 exp 값만 저장하면 설계가 끝난다. <br/>이때 지수부와 가수부에 할당하는 비트 수에 따라 표현 범위와 정밀도가 결정된다. <br/>0 0000 000 > 부호, 지수부, 가수부 <br/><br/>
- 실수 역시 정수와 마찬가지로 첫 번째 비트는 부호를 나타낸다. <br/>0이면 양수고 1이면 음수이다. <br/>가운데 4비트는 지수부로 exp 값, 맨 뒤 3비트는 가수부로 man 값을 저장한다. <br/><br/>
- bias는 지수의 부호를 결정하는 데 쓴다. <br/>부동소수점의 지수부에는 부호 비트가 없으며 0~15의 양수만 나타낼 수 있다. <br/>하지만 음수 지수도 필요하다. <br/>음수를 사용하려면 bias를 7로 두고 지수부(exp)에서 bias를 뺀 값을 실제 지수로 사용한다. <br/>bias는 2<sup>n-1</sup>-1 식에 지수부의 비트 수인 4를 대입하면 구할 수 있다. <br/><br/>
- 정규화된 수 1.1111x2<sup>2</sup>에서 실제 지수는 2이다. <br/>실제 지수가 2라는 의미는 exp-bias가 2라는 것이다. <br/>지수부의 비트 수 4를 식(2<sup>n-1</sup>-1)에 대입해 얻은 bias 값이 7이므로 실제로 부동소수점의 지수부에 나타나는 값 exp는 9가 된다.

<br/>

- 부호 -> 0
- 지수부 -> 1001
- 가수부 -> 1111

<br/>

- 가수부는 3비트만 할당되는 데 가진 값은 1111일 경우, 뒷자리 1을 생략한다. <br/>즉, 가수부는 111이 된다. <br/><br/>
- 0 1001 111 = 0100 1111 = 0x4f <br/>즉, 실수 7.75를 1바이트 부동소수점으로 나타내면 0x4f이다.

<br/>

### 1바이트 부동소수점의 표현 범위

![image](https://user-images.githubusercontent.com/61584142/158999639-746107e9-bca5-4b5d-95d5-2c5148e6a499.png)

- 단, 지수부 비트가 모두 0일 때 (2<sup>-7</sup>)와 모두 1일 때(2<sup>8</sup>)는 0.0, 정규화 불가능, 무한대, NaN(Not a Number, 숫자가 아님) 같은 특별한 상황을 나타내므로 제외한다. <br/><br/>
- 1바티으지만 굉장히 작은 수부터 큰 수까지 폭넓게 표현할 수 있다는 것을 알 수 있다.

<br/><br/><br/>

### 1바이트 부동소수점의 정밀도
- 1바이트 부동소수점 설계를 마쳤는데 석연치 않은 점이 하나 있다. <br/>변환 과정에서 가수부를 담을 공간이 부족해 가수부에 들어갈 데이터인 1111에서 맨 뒤에 있는 1을 누락했는데, 이렇게 되면 0x4f는 7.75라는 실수를 완벽하게 표현하지 못한다. <br/><br/>
- 1.111 x 2<sup>2</sup> = 1 x 2<sup>2</sup> 1 x 2<sup>1</sup> + 1 x 2<sup>0</sup> + 1 x 2<sup>-1</sup> = 7.5 <br/>0.25만큼 차이가 나므로 정밀도가 그만큼 떨어진다. 

<br/><br/><br/>

## 정밀도에 대한 고찰
### 엡실론
- 실수 자료형에서 엡실론(epsilon)이란 1.0과 그 다음으로 표현 가능한 수(representable float) 사이의 차이를 말한다.
<pre><code>import sys
sys.float_info.epsilon # 2.220446049250313e-16</code></pre>
- 위 코드는 sys 모듈의 float_info에 있는 epsilon을 출력한 결과이다. <br/><br/>
- 파이썬이 사용하는 배정도(double)의 가수부가 52비트라고 했다. <br/>1.0을 배정도에 맞춰 표현하면 다음과 같다. <br/>1.0000 …… 0000(0: 52개) × 2<sup>0</sup> <br/><br/>
- 배정도에서 1.0 다음으로 표현할 수 있는 수(representable float)는 다음과 같다. <br/>1.0000 …… 0001(0: 51개, 1: 마지막 비트) × 2<sup>0</sup> <br/><br/>
- 따라서 두 수의 차이는 다음과 같다. <br/>0.0000 …… 0001(0: 51개, 1: 마지막 비트) × 2<sup>0</sup>
- 이 수를 10진수로 바꾸면 엡실론 값이 나온다. <br/>2.220446049250313 × 10<sup>-16</sup>

<br/>

### 엡실론과 정밀도
- 어떤 실수가 있을 때 엡실론을 이용하면 그 실수 다음에 표현할 수 있는 수를 알아낼 수 있다. <br/>예를 들어, 배정도 실수 9.25를 부동소수점 방식으로 표현하면 1.00101 x 2<sup>3</sup>이다. <br/>이 식에서 지수 부분만 떼어 내 엡실론을 곱하면 이 실수와 다음 표현 가능한 수 사이의 차이를 구할 수 있다.
<pre><code>import sys
ep = sys.float_info.epsilon
a = 9.25
diff = (2**3)*ep  #1
diff # 1.7763568394002505e-15

b = a + diff      #2
b # 9.250000000000002</code></pre>
- #1에서 diff는 지수 부분인 2<sup>3</sup>에 엡실론을 곱한 값으로 9.25와 그 다음 표현 가능한 수 사이의 차이이다. <br/>#2에서 b는 a에 diff를 더했으므로 9.25 다음에 표현 가능한 수를 나타낸다.

<br/>

#### 9.25에 diff보다 작은 값을 더하면 어떻게 될까?
<pre><code>a # 9.25

half_diff = diff/2                  #1
half_diff # 8.881784197001252e-16   #2

c = a + half_diff                   #3
a = = c # True                      #4</code></pre>
- half_diff는 diff 값의 반절이다(#1). <br/>half_diff 역시 실수를 나눠서 얻은 값이니 실수이다(#2). <br/>a와 half_diff를 더해 c에 대입한다(#3). <br/>실수와 실수를 더했으므로 c는 반드시 a보다 커야 한다. <br/>그런데 a값과 c값이 같다고 나온다(#4). <br/><br/>
- a 값과 c 값이 같은 이유는 c에 더한 half_diff 값이 diff보다 작기 때문이다. <br/>diff는 9.25와 그 다음 표현 가능한 수 사이의 차이이므로 9.25에 diff보다 작은 값을 더한 수를 부동소수점 방식에서는 표현할 수 없다. <br/>달리 표현하면 정밀도가 떨어진다는 말이다.

<br/>

#### 부동소수점의 정밀도에 관한 예
<pre><code>a = (2.0)**53
a # 9007199254740992.0

b = a + 1.0
a = = b # True</code></pre>
- a는 1.0000 …… 0000(0: 52개) × 2<sup>53</sup>이다. <br/>a와 a 다음에 표현 가능한 수 사이의 차이는 2<sup>53</sup>에 엡실론을 곱해 구할 수 있으며 그 값은 2.0이다. <br/>그러므로 a에 1.0을 더한 b는 원래 의도한 값을 표현하지 못하고 a와 같은 값을 갖게 된다. <br/>1.0의 차이조차 표현할 수 없는 정밀도이다.

<br/>

> - 0.01을 100번 더했을 때 정확하게 1이 나오지 않는 이유를 알 수 있다. <br/>
> - 부동소수점은 지수부에 따라 아주 작은 수와 아주 큰 수를 표현할 수 있지만, 어떤 상황에서는 16과 17같이 큰 단위의 정수조차 제대로 표현할 수 없을 때도 있다. <br/>'표현 범위는 넓지만 정밀도는 낮다'는 말의 의미를 정확하게 이해할 수 있다.

---

<br/><br/><br/><br/>

# 4장 문자와 문자열
- 수와 함께 가장 많이 사용되는 기본 자료형은 문자와 문자열이다. <br/>프로그래밍을 하다 보면 문자열을 다룰 일이 많다.

<br/><br/><br/>

## 아스키코드
- 문자 인코딩(character encoding)은 문자 집합을 메모리에 저장하거나 통신하는 데 사용하기 위해 부호화하는 방식을 말한다. <br/>대표적인 예로 모스 부호를 들 수 있다. <br/><br/>
- 문자 집합(character set)은 문자(character)를 모아 둔 것이다. <br/>예를 들면 라틴 문자가 있다. <br/>주목할 점은 다양한 언어(영어, 프랑스어, 독일어 등)가 라틴 문자를 사용한다는 점이다. <br/><br/>
- 0과 1밖에 모르는 컴퓨터에 문자를 인식시키려면 문자를 0과 1로 이루어진 2진수로 나타내야 한다. <br/>문자 하나에 정수 하나를 매핑해 두면 이 정수는 특정 문자를 표현하게 된다. <br/>이렇게 매핑된 정수를 코드 포인트(code point)라고 하고, 문자와 문자에 매핑된 코드 포인트를 모아 놓은 집합을 부호화횐 문자 집합(Coded Character Set, CCS)이라고 한다.

<br/>

- 아스키(American Standard Code for Information Interchange, 미국정보교환표준부호)는 대표적인 문자 인코딩 방식이다. <br/>비트 일곱 개로 문자를 표현하므로 문자를 총 128개까지 표현할 수 있다. <br/>당연히 코드 포인트 수도 128개이다.

![image](https://user-images.githubusercontent.com/61584142/159110367-3ab3974d-d35e-40ba-823d-2e9c87ac19cd.png)

- 0부터 127까지 총 128개 코드 포인트에 128개 문자가 매핑된 것을 확인할 수 있다. <br/>처음에 보이는 네 개의 열(Decimal, Hexadecimal, Binary, Octal)은 코드 포인트를 진수별로 변환한 것이고 마지막 열(Char)은 해당 코드 포인트에 매핑된 문자이다.

<br/>

- 예를 들어 대문자 'A'는 10진수로는 65고 16진수로는 0x41이다. <br/>소문자 'a'는 10진수로는 97이고 16진수로는 0x61이다. <br/>숫자 문자인 '0'은 10진수로는 48이고 16진수로는 0x30이다.
<pre><code>ch = 'A'
bch = ch.encode()
bch # b'A'

bch[0] # 65</code></pre>
- 마지막 출력 값을 보면 대문자 'A'가 정수 65와 매핑되었음을 알 수 있다. 

<br/>

<pre><code>ch_0 = '0'
bch_0 = ch_0.encode()
bch_0 # b'0'

bch_0[0] # 48</code></pre>
- 숫자 문자 '0'은 정수 48과 매핑되었음을 알 수 있다. <br/>

<br/>

- 아스키코드를 보면 정수 0부터 127까지 문자와 매핑되어 있다. <br/>2진수로 0000 0000(0)부터 0111 1111(127)까지이므로 표현하는 데 최대 7비트가 필요하다. <br/>정수를 나타내는 데 쓰는 자료형은 바이트 수에 따라 다양한데, int형이 가장 많이 쓰인다. <br/>int형은 32비트 컴퓨터에서 일반적으로 4바이트(32비트)이다. <br/>이보다 작은 short형은 2바이트(16비트)이다. <br/>아스키코드를 표현하는 데 7비트면 충분하므로 int형이나 short형을 쓰면 메모리가 낭비된다. <br/>그래서 문자를 표현하기 위해 char형이라는 새로운 정수 자료형을 만들었다. <br/>char형은 문자를 담기 위해 만들어진 자료형이지만 정수 자료형이므로 작은 수를 표현하는 데 사용하기도 한다.

<br/><br/><br/>

## 유니코드
- 아스키코드를 보면 알파벳만 있고 한글이 없다. <br/>아스키코드만 보면 우리는 컴퓨터에서 한글을 사용할 수 없을 것 같다. <br/>하지만 우리는 컴퓨터에서 한글을 쓰고 있다. <br/>한글은 아스키코드의 범위를 벗어나는데 우리는 어떻게 한글을 쓰고 있는 걸까? <br/><br/>
- 전 세계적으로 컴퓨터가 보급되고 인터넷을 통해 세계 각국의 사람들이 커뮤니케이션을 하면서 컴퓨터에서 쓸 수 있는 언어가 좀 더 많이 필요해졌다. <br/>이때 나온 해결 방법이 7비트로 표현한 문자를 16비트로 확장하는 것이었다. <br/>7비트일 때는 128개 문자를 표현할 수 있지만 16비트로 확장하면 65,536개 문자를 표현할 수 있다. <br/>여기에 더해 수 하나에 다시 문자 하나를 일대일로 대응한 새로운 표를 만들었는데, 이 테이블이 바로 유니코드이다. <br/><br/>
- 이에 처음부터 새로 대응한 것은 아니고 아스키코드인 0x0000부터 0x007F(2진수 0000 0000 0000 0000 ~ 0000 0000 0111 1111 즉, 기존 아스키코드 앞에 0으로 채워진 8비트를 붙인 것)까지는 그대로 유지하고 이후부터 숫자 하나에 문자 하나씩을 대응하였다. <br/>문자에는 한글, 중국어, 일본어 같은 언어 대부분이 포함되어있다. <br/><br/>
- 유니코드를 만든 사람은 여기서 한발 더 나아갔다. <br/>아스키코드를 만들었을 때 문자를 표현할 숫자가 모자라는 상황을 예측하지 못했듯이, 이번에도 2바티으면 충분할 것 같지만 미래는 알 수 없는 일이기 때문이다. <br/>언어 대부분이 포함된 이 첫 번째 테이블을 기본 다구어 평면(Basic Multilingual Plane, BMP)이라 이름 짓고, 이러한 테이블을 총 열일곱 개나 준비해 두었다(이 평면 중 대부분은 아직 정의되지 않았다). <br/><br/>
- 유니코드를 알게 되었으니 우리의 관심사는 한글이다. <br/>한글을 기본 다국어 평면 어디부터 어디까지에 위치해 있을까? <br/>한글은 U+AC00부터 U+D7AF까지에 자리 잡고 있다. <br/>U+는 유니코드라는 의미고 2바이트 수인 AC00은 한글 '가'를 의미한다.

<br/>

![image](https://user-images.githubusercontent.com/61584142/159110864-c2dacb43-4159-41b2-adee-6cc3aff155f0.png)

- 유니코드는 어떻게 읽을까? <br/>왼쪽에 위치한 숫자 AC00을 보면 해당하는 열에서 0을 더한 숫자 AC00이 '가'를 의미한다. <br/>AC00에 1을 더한 AC01은 '각'을 의미한다.

![image](https://user-images.githubusercontent.com/61584142/159110895-782a6525-4dd9-4a03-9eee-9ed9862561a8.png)

<br/>

- 파이썬에서도 유니코드 문자를 확인할 수 있다.
<pre><code>'\uAC00' # '가'
'\uAC01' # '각'</code></pre>

<br/><br/><br/>

## 유니코드 인코딩 방식
- 코드 유닛(code unit)은 코드 포인트를 특정한 방법으로 인코딩했을 때 변환되어 얻어지는 비트의 나열을 말한다. <br/><br/>
- 문자 인코딩 방식(Character Encoding Scheme, CES)은 코드 유닛을 옥텟으로 나열하여 변환하는 방법이다. <br/>옥텟(octet)은 데이터의 단위로 8비트를 의미한다. <br/>지금은 1바이트를 당연히 8비트라고 생각하지만, 예전에는 1바이트가 반드시 8비트는 아니었으므로 옥텟이라는 용어를 따로 사용했다. <br/>현재 컴퓨터는 모두 8비트 단위를 사용하므로 코드 유닛을 옥텟으로 변환해도 실제로 비트가 바뀌지는 않는다. <br/><br/>
- 유니코든느 2바이트로 숫자 하나에 문자 하나를 대응하여 문자를 표현한다. <br/>기본 다구그어 평면을 포함해 평면이 열일곱 개 있으므로 모든 문자를 표현하려면 3바이트가 필요하다. <br/>언뜻 생각하면 코드 유닛의 크기를 3바이트로 하고 코드 포인트를 그대로 저장하면 될 것 같지만 그렇게 쉽게 결정할 문제가 아니다. <br/><br/>
- 만약 1바이트 정수만 저장할 수 있는 시스템이라면 3바이트짜리 정수는 저장할 수 없으므로 이 시스템에서는 한글을 표현할 수 없다. <br/>그러므로 다양한 코드 유닛을 갖는 인코딩 방식을 두어 유연하게 대처해야 한다. <br/>유니코드 인코딩 방식에도 다양한 종류가 있지만 여기서는 UTF-8, UTF-16, UTF-32에 대해서만 다루겠다. 

<br/>

#### 인코딩 방식에 따른 자료형 C++ 코드
<pre><code>char * str1 = u8"가";
char16_t * str2 = u"가";
char32_t * str3 = U"가";</code></pre>

<br/>

### encode() 함수
- 파이썬에서 encode() 함수는 문자를 주어진 유니코드 인코딩 방식에 따라 코드 유닛을 나열하는 방식으로 변환하는 함수이다. <br/>
- 다음은 한글 '가'(유니코드 코드 포인트: U+AC00)를 각 인코딩 방식으로 변환한 결과이다.
<pre><code>ch = '가'
ch.encode() # b'\xea\xb0\x80'

ch.encode('UTF-8')  # b'\xea\xb0\x80'
ch.encode('UTF-16') # b'\xff\xfe\x00\xac'
ch.encode('UTF-32') # b'\xff\xfe\x00\x00\x00\xac\x00\x00'</code></pre>
- encode() 함수의 인자 중 하나인 인코딩 방식을 각각 다르게 적용하면 결과 값과 크기가 모두 다르게 나타나는 것을 확인할 수 있다. <br/>encode() 함수의 인자에 아무것도 전달하지 않으면 'UTF-8'이 인자일 때와 값이 같으므로 파이썬에서는 기본값이 UTF-8이라는 것도 알 수 있다.

<br/>

### UTF-8
- UTF-8(Universal Coded Character Set Transformation Format-8 bit)은 유니코드 인코딩 방식 중 하나로 유니코드 문자 하나를 1바이트에서 4바이트 사이에서 표현한다. <br/>유니코드 코드 포인트가 U+0000 ~ U+007F는 1바이트, U+0080 ~ U+07FF는 2바이트, U+0800 ~ U+FFFF는 3바이트, 나머지는 4바이트로 표현한다. <br/>문자에 따라 바이트 수가 달라지므로 가변 길이 인코딩 방식이라고 부른다.
<pre><code>char * str1 = u8"가";</code></pre>
- 문자열 "가" 앞에 붙은 u8은 UTF-8을 의미한다. <br/>str1은 UTF-8로 인코딩된 문자열 "가"가 저장된 메모리 공간을 가리킨다. <br/>주목해야 할 점은 유니코드인데도 1바이트짜리 char 자료형에 데이터를 담는다는 점이다. <br/>문자 '가'의 코드 포인트 U+AC00은 U+0800 ~ U+FFFF 사이의 수이므로 3바이트로 표현될 것이다. <br/><br/>

![image](https://user-images.githubusercontent.com/61584142/159111173-143e1dd1-efac-4aa0-bfee-41a246df62d9.png)
- UTF-8로 인코딩된 문자 '가'가 실제 메모리에 어떻게 저장되어 있는지 보여준다. <br/>예상대로 3바이트로 표현되어 있다(메모리 주소는 큰 의미가 없다).

<br/>

#### U+AC00은 어떻게 0xEAB080으로 변환되었을까?
- UTF-8에서 코드 포인트가 U+0800에서 U+FFFF 사이인 문자는 다음과 같은 포맷으로 변환된다.

![image](https://user-images.githubusercontent.com/61584142/159111308-9cddf23b-bb97-450b-978d-59fc355cfa15.png)

<br/>

- 포맷을 천천히 살펴보자. <br/>이 포맷에서 맨 앞에 있는 111은 바이트 수를 나타낸다. <br/>1바이트로 표현되면 1, 2바이트로 표현되면 11, 3바이트로 표현되면 111이다. <br/>X로 표시된 부분은 문자의 코드 포인트를 2진수로 변환한 후 차례대로 채운다. <br/><br/>

- 문자 ‘가’의 코드 포인트 U+AC00을 2진수로 표현하면 다음과 같다.

![image](https://user-images.githubusercontent.com/61584142/159111334-6f3b7675-d23d-4d89-9b8d-1c101df8fb33.png)

<br/>

- 포맷의 X를 보면 첫번째 등장하는 X는 4자리, 그 다음은 6자리, 마지막은 6자리이다. <br/>이 자리수에 맞춰 변환해 둔 2진수 수(문자 ‘가’의 코드 포인트)를 표현해 보자.

![image](https://user-images.githubusercontent.com/61584142/159111350-ff9a2090-6e08-4b00-95d4-ea9bdb20d8a1.png)

<br/>

- 이제 포맷의 X를 이 수로 채운다.

![image](https://user-images.githubusercontent.com/61584142/159111357-314ce5fb-9df8-47e2-a86d-2071368c9533.png)
- 이를 16진수로 변환하면 0xEAB080 이다.

<br/><br/>

### UTF-16
- UTF-16도 유니코드 인코딩 방식 중 하나로 2바이트 단위로 문자를 표현한다. <br/>해당 문자가 기본 다국어 평면에 있으면 2바이트로 인코딩되고, 그렇지 않으면 4바이트로 인코딩된다. <br/>코드 유닛의 크기는 16바이트이다.
<pre><code>char16_t * str2 = u"가";</code></pre>
- 문자열 "가" 앞에 붙은 소문자 u는 UTF-16으로 인코딩하겠다는 의미이다. <br/>char16_t는 C++ 언어에서 UTF-16 인코딩 방식으로 변환된 데이터를 담기 위해 만들어진 자료형으로 2바이트이다. <br/>그러면 문자 ‘가’는 메모리에 어떻게 저장되어 있을까?

<br/>

#### 문자 ‘가’가 UTF-16으로 인코딩되어 메모리에 담긴 모습이다.
![image](https://user-images.githubusercontent.com/61584142/159111426-727cf80f-77ca-4745-8877-dda2fad7dee8.png)
- 값이 매우 낯익다. <br/>문자 '가'의 코드 포인트인 AC00을 바이트 단위로 순서만 바꾸었다. <br/>문자 '가'는 기본 다국어 평면에 있으므로 2바이트로 표현된다.

<br/><br/>

### UTF-32
- 유니코드 인코딩 방식의 하나로 모든 문자를 4바이트로 표현한다. <br/>코드 유닛의 크기는 32비트이다.
<pre><code>char32_t * str3 = U"가";</code></pre>
- UTF-32는 모든 문자를 4바이트 단위로 인코딩하므로 기본 다국어 평면의 문자뿐만 아니라 모든 평면에 있는 문자를 한 개 단위로 담을 수 있다. <br/> char32_t는 4바이트 자료형으로 UTF-32로 인코딩된 데이터를 담기 위해 만들어졌다. <br/><br/>

<br/>

#### 문자 ‘가’가 UTF-32로 인코딩되어 메모리에 담긴 모습이다.
![image](https://user-images.githubusercontent.com/61584142/159111474-8ccd4f8b-a52c-45d0-965a-107e0b199a97.png)
- 모든 문자가 4바이트로 표현되므로 문자 '가'도 4바이트로 표현된다.

<br/><br/><br/>

## 파이썬 문자열의 특징
- C/C++에서는 문자열을 변수로 만들면 요소인 문자를 변경할 수 있고, 문자열을 상수로 만들면 요소를 변경할 수 없다. <br/>즉, 프로그래머가 변경 가능성을 선택할 수 있다. <br/><br/>
- 하지만 파이썬의 문자열은 요소를 변경할 수 없다. <br/>변경을 시도하는 순간 오류가 발생한다.
<pre><code>string = 'abcde'
string[2] = 'a'</code></pre>

```
Traceback (most recent call last):
    File "<pyshell#3>", line 1, in <module>
       string[2] = 'a'
TypeError: 'str' object does not support item assignment
```

<br/>

- 문자열 string에서 가운데 위치한 c를 x로 변경하고 싶다면, 문자열 슬라이싱(slicing)을 사용해 요소를 변경한다. <br/>주의해야 할 점은 string의 요소를 직접 변경하지 않았다는 점이다.
<pre><code>new_string = string[:2] + 'x' + string[3:]
new_string # 'abxde'</code></pre>

<br/>

- 파이썬에서 문자열을 변경하는 다른 방법도 있다. <br/>내장함수(Built-in function)중 하나인 replace() 함수를 사용하여 변경하는 방법이다. <br/>replace() 함수 인자에 기존 문자열과 바꿀 문자열을 전달하면 바뀐 문자열을 반환한다. <br/>하지만 이번에도 string의 요소를 직접 변경하지 않았다.
<pre><code>string = 'abcde'
new_string = string.replace(‘c’, ‘x’)
new_string # ‘abxde’

string # ‘abcde’</code></pre>

<br/>

> 프로그래밍을 하다 보면 텍스트 파일을 열었을 때 문자가 깨지는 현상과 같은 문자 인코딩 문제를 종종 만나니다. <br/>이때 문자에 대한 지식이 부족하면 문제가 왜 발생했는지 파악하느라 오랜 시간을 보낼 수 있다. <br/>문자 인코딩에 대해 정확한 지식을 갖춰 두면 이럴 때 문제를 빠르게 파악할 수 있어 매우 유용하다.

---

<br/><br/><br/><br/>

# 5장 함수
- 프로그래밍에서는 함수의 작동 방식을 정확히 이해하는 것이 매우 중요하다. <br/>그러려면 전역 변수와 지역 변수와 스택 프레임을 먼저 알아야 한다. <br/>그런 다음에는 함수를 호출할 때 인자를 전달하는 방식에 따라 실행 결과가 어떻게 달라지는지 이해해야 한다.

<br/><br/><br/>

## 함수를 시작하기 전에
### 자료 구조 미리 엿보기
- 함수의 작동 원리를 이해하려면 스택의 개념을 반드시 알아야 한다. <br/>스택은 접시 쌓기라고 생각하면 된다. <br/>데이터를 저장할 때 접시처럼 차곡차곡 쌓아 올리고, 데이터를 꺼낼 때는 접시처럼 맨 위부터 차례차례 내린다. <br/>즉, 마지막에 들어온 데이터가 가장 먼저 나간다. 

<br/>

### 전역 변수와 지역 변수
#### 전역 변수
- 전역 변수(global variable)는 전체 영역에서 접근할 수 있는 변수이다. <br/>따라서 함수 안에서도 접근할 수 있어야 한다.
<pre><code>g_var = 10         #1

def func():
    print("g_var = {}".format(g_var))

if __name__ = = "__main__":
    func()</code></pre>

`g_var = 10`

- g_var은 전역 변수이다(#1). <br/>함수 안에서 전역 변수에 접근했고, 실행 결과를 보면 접근이 가능하다는 것을 알 수 있다.

<br/>

- 이번에는 함수 안에서 전역 변수의 변경을 시도해 보자.
<pre><code>g_var = 10       #1

def func():
    g_var = 20   #2
    print("g_var = {} in function".format(g_var))  #3

if __name__ = = "__main__":
    func()
    print("g_var = {} in main".format(g_var))      #4</code></pre>
```
g_var = 20 in function
g_var = 10 in main
```
- 전역 변수 g_var을 선언했고(#1) 함수 안에서 g_var 값의 변경을 시도한다(#2). <br/>전역 변수가 함수 안에서 변경되었는지 출력하여 확인해 보자(#3). <br/>또한 함수 바깥 즉, 함수를 호출한 쪽에서 변경되었는지도 출력해 확인해 보자(#4).<br/><br/>
- 실행 결과를 보면 당혹스럽다. <br/>분명 함수 안에서는 g_var 값이 20으로 변경되었는데 함수 바깥에서 확인해 보니 바뀌지 않았다. <br/>왜 이런 결과가 나온걸까? <br/>그 이유는 함수 안에서 전역 변수 g_var 값의 변경을 시도하기 위해 선언한 #2는 전역 변수를 변경하는 것이 아니라 함수 안에서 새로운 지역 변수 g_var을 생성한 것이기 때문이다.

<br/>

#### 지역 변수
- 지역 변수(local variable)는 전역 변수와 반대 개념이다. <br/>말 그대로 특정 지역에서만 접근할 수 있는 변수이다. <br/>특정 지역은 함수 내부를 의미한다. <br/>따라서 함수 안에서 선언한 변수가 지역 변수이다. <br/>지역 변수는 함수 바깥에서는 접근할 수 없고 함수가 호출될 때 생성되었다가 호출이 끝나면 가라진다. <br/><br/>
- 함수 안에서 변수를 선언하는 #2는 지역 변수를 생성하는 코드이다. <br/>함수 안에서 전역 변수를 변경하려면 특별한 문법이 필요하다.
<pre><code>g_var = 10            #1

def func():
    global g_var      #2
    g_var = 20        #3

if _ _name__ = = "__main__":
    print("g_var : {} before".format(g_var))
    func()
    print("g_var : {} after".format(g_var))</code></pre>

```
g_var = 20 in function
g_var = 10 in main
```
- 코드를 보면 #1에서 선언한 전역 변수를 #3에서 변경하였다. <br/>실행 결과를 보면 잘 변경된 것을 확인할 수 있는데 그 이유는 #2에서 global 키워드를 이용해 전역 변수 g_var을 함수 안에서 사용하겠다고 명시했기 때문이다. <br/>따라서 #3은 지역 변수를 따로 생성한 것이 아니라 전역 변수 g_var을 변경하는 것을 의미한다. <br/><br/>

##### 전역 변수에 대한 접근과 변경에 대해 알아보았으니 지역 변수의 특징에 대해서도 알아보자.
#### nonlocal 키워드
- 함수 안에서 전역 변수를 변경할 수 있다는 것을 알았다. <br/><br/>
- 함수를 정의할 때 함수 내부에서 다른 함수를 정의할 수 있다.
<pre><code>def outer():
    a = 10          #1

    def inner():
        b = 20      #2</code></pre>
- 코드에서 outer() 함수에 지역 변수 a가 선언되었고(#1), 중첩된 함수 inner() 함수에 지역 변수 b가 선언되었다(#2). <br/>한 가지 생각해 볼 문제는 inner() 함수에서 outer() 함수의 지역 변수인 a를 변경할 수 있는지이다. <br/>변수 a는 outer() 함수 입장에서는 지역 변수지만 inner() 함수 입장에서는 지역 변수가 아니다. <br/>inner() 함수의 지역 변수는 b이다.

<br/>

<pre><code>a = 1

def outer():
    b = 2
    c = 3
    print(a, b, c)
    def inner():
        d = 4
        e = 5
        print(a, b, c, d, e)        #1
    inner()

if __name__ = = "__main__":
    outer()</code></pre>
    
```
1 2 3
1 2 3 4 5
```
- 코드를 보면 outer() 함수의 공간에 b와 c가 있고 중첩된 inner() 함수의 공간에는 d와 e가 있다. <br/>inner() 함수에서는 전역 변수뿐만 아니라 outer() 함수의 공간에 있는 지역 변수에도 접근할 수 있다(#1). <br/>하지만 전역 변수 예제에서 살펴본 것처럼 inner() 함수 안에서 b와 c를 바꾸려고 시도하면 outer() 함수 공간에 접근하는 것이 아니라 inner() 함수 공간 안에 b와 c라는 지역 변수를 생성한다. <br/>b나 c는 전역 변수가 아니니 global 키워드를 사용할 수도 없다. <br/>inner() 함수 안에서 b와 c를 변경하려면 nonlocal 키워드를 사용하면 된다.

<br/>

<pre><code>def outer():
    a = 2           #1
    b = 3

    def inner():
        nonlocal a  #2
        a = 100     #3
    inner()

    print(
    "locals in outer : a = {}, b = {}".format(a, b))
if __name__ = = "__main__":
    outer()</code></pre>

```
locals in outer : a = 100, b = 3
```
- 코드를 보면 #1에서 선언한 outer() 함수의 지역 변수 a를 #3에서 변경하였다. <br/>실행 결과를 보면 잘 바뀌었다. <br/>#2에서 nonlocal 키워드로 inner() 함수 안에서 outer() 함수의 지역 변수 a를 사용할 것이라고 선언했기 때문이다.

<br/><br/><br/>

## 인자 전달 방식에 따른 분류
- 이번에는 함수의 작동 원리를 알아보자. <br/>함수는 인자(argument) 전달 방식에 따라 크게 값에 의한 전달(call by value)과 참조에 의한 전달(call by reference)로 나누어진다. <br/>프로그래밍을 공부할 때 꼭 한 번은 거쳐야 하는 개념이다. <br/>파이썬은 값에 의한 전달과 참조에 의한 전달 방식을 이용하지 않으므로 두 가지 전달 방식을 파이썬으로 설명하기는 어렵다.

<br/><br/>

### 값에 의한 전달
```
#include <iostream>
using namespace std;

void change_value(int x, int value) // #1
{
    x = value;                      // #2
    cout << “x : “ << x << ” in change_value” << endl;
}

int main(void)
{
    int x = 10;                     // #3
    change_value(x, 20);            // #4
    cout << “x : “ << x << ” in main” << endl;

<span class="k">return</span> <span class="mi">0</span><span class="o">;</span>
}
```

#### 실행결과

```
x : 20 in change_value
x : 10 in main
```

<br/>

#### 코드를 읽는 데 필요한 C++ 문법 요약
- #include나 using 부분은 신경 쓰지 않아도 된다. <br/>주목해야 할 곳은 #1의 함수 정의 부분이다. <br/>파이썬은 변수를 선언할 때 자료형을 명시하지 않지만, C++에서는 컴파일러에 알려 줘야 하므로 반드시 명시해야 한다. <br/>같은 이유로 함수에서도 함수 정의 맨 앞에 반환형을 명시해야 한다. <br/>파이썬에서는 구현부를 보지 않으면 반환형을 알 수 없는 것과 대비된다.

<br/>

- 인자 전달 부분은 자료형이 명시되어 있는 것만 빼면 파이썬과 유사하다. <br/>함수 정의에서 등장하는 { } 기호는 스코프라고 하며 영역을 의미한다. <br/>우리는 전역 변수와 지역 변수를 공부했기 때문에 영역의 의미를 알고 있다. <br/>파이썬은 명시적인 { } 기호가 없는 대신에 들여쓰기(indentation)로 영역을 나타낸다. <br/>몇 가지 차이점만 빼면 파이썬과 C++의 문법은 비슷하다.

<br/>

- 코드에서 change_value() 함수는 인자 x와 value를 받아 x에 value를 대입한다. <br/>main() 함수에서 지역 변수 x에 10을 대입한 다음 change_value() 함수를 호출하면서 value 인자로 20을 전달했으므로 지역 변수 x 값은 20으로 바뀔 것 같지만, 실행 결과를 보면 예상과 다른 값이 출력된다.

<br/>

- 함수 안에서는 값이 변경되었지만 함수를 호출한 쪽에서는 값이 변경되지 않았다. <br/>지역 변수 x가 변경되지 않은 이유는 함수에 x가 전달될 때 값에 의한 전달 방식으로 전달되었기 때문이다. 

---

<br/><br/><br/><br/>

# 6장

---

<br/><br/><br/><br/>

# 7장

---

<br/><br/><br/><br/>

# 8장

---

<br/><br/><br/><br/>

# 9장

---

<br/><br/><br/><br/>

# 10장

---

<br/><br/><br/><br/>

# 11장

---

<br/><br/><br/><br/>

# 12장

---

<br/><br/><br/><br/>

# 13장

---

<br/><br/><br/><br/>

# 14장

---

<br/><br/><br/><br/>

# 15장

---

<br/><br/><br/><br/>
